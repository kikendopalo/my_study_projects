{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "5g8Po55pRU11"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class LinReg(BaseEstimator):\n",
        "    def __init__(\n",
        "        self,\n",
        "        delta=1.0,\n",
        "        gd_type=\"Momentum\",\n",
        "        tolerance=1e-4,\n",
        "        max_iter=2000,\n",
        "        w0=None,\n",
        "        eta=1e-2,\n",
        "        alpha=1e-3,\n",
        "        epsilon=1e-2,\n",
        "        reg_cf=1e-2,\n",
        "        rms_prop_cf=1 - 1e-7,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        gd_type: str\n",
        "            'GradientDescent', 'StochasticDescent', 'Momentum', 'Adagrad'\n",
        "        delta: float\n",
        "            proportion of object in a batch (for stochastic GD)\n",
        "        tolerance: float\n",
        "            for stopping gradient descent\n",
        "        max_iter: int\n",
        "            maximum number of steps in gradient descent\n",
        "        w0: np.array of shape (d)\n",
        "            init weights\n",
        "        eta: float\n",
        "            learning rate\n",
        "        alpha: float\n",
        "            momentum coefficient\n",
        "        reg_cf: float\n",
        "            regularization coefficient\n",
        "        epsilon: float\n",
        "            numerical stability\n",
        "        \"\"\"\n",
        "\n",
        "        self.delta = delta\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = (\n",
        "            None  # list of loss function values at each training iteration\n",
        "        )\n",
        "        self.epsilon = epsilon\n",
        "        self.reg_cf = reg_cf\n",
        "        self.rms_prop_cf = rms_prop_cf\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        if self.gd_type == \"GradientDescent\":\n",
        "            self.loss_history = []\n",
        "            if self.w0 is None:\n",
        "                self.w = np.random.normal(size=X.shape[1])\n",
        "            else:\n",
        "                self.w = self.w0\n",
        "            for i in range(self.max_iter):\n",
        "                self.loss_history.append(self.calc_loss(X, y))\n",
        "                w_new = self.w - self.eta * self.calc_gradient(X, y)\n",
        "                if (np.abs(w_new - self.w)).mean() < self.tolerance:\n",
        "                    break\n",
        "                self.w = w_new\n",
        "\n",
        "        elif self.gd_type == \"StochasticDescent\":\n",
        "            self.loss_history = []\n",
        "            if self.w0 is None:\n",
        "                self.w = np.random.normal(size=X.shape[1])\n",
        "            else:\n",
        "                self.w = self.w0\n",
        "            for i in range(self.max_iter):\n",
        "                X_sample = X.sample(frac=self.delta, random_state=i)\n",
        "                y_sample = y.sample(frac=self.delta, random_state=i)\n",
        "                self.loss_history.append(self.calc_loss(X_sample, y_sample))\n",
        "                w_new = self.w - self.eta * self.calc_gradient(X_sample, y_sample)\n",
        "                if (np.abs(w_new - self.w)).mean() < self.tolerance:\n",
        "                    break\n",
        "                self.w = w_new\n",
        "\n",
        "        elif self.gd_type == \"Momentum\":\n",
        "            self.loss_history = []\n",
        "            if self.w0 is None:\n",
        "                self.w = np.random.normal(size=X.shape[1])\n",
        "            else:\n",
        "                self.w = self.w0\n",
        "            h = 0\n",
        "            for i in range(self.max_iter):\n",
        "                self.loss_history.append(self.calc_loss(X, y))\n",
        "                h_new = self.alpha * h + self.eta * self.calc_gradient(X, y)\n",
        "                w_new = self.w - h_new\n",
        "                if (np.abs(w_new - self.w)).mean() < self.tolerance:\n",
        "                    break\n",
        "                self.w = w_new\n",
        "                h = h_new\n",
        "\n",
        "        elif self.gd_type == \"RMSProp\":\n",
        "            self.loss_history = []\n",
        "            if self.w0 is None:\n",
        "                self.w = np.random.normal(size=X.shape[1])\n",
        "            else:\n",
        "                self.w = self.w0\n",
        "            g = 0\n",
        "            for i in range(self.max_iter):\n",
        "                self.loss_history.append(self.calc_loss(X, y))\n",
        "                g_new = (\n",
        "                    self.rms_prop_cf * g\n",
        "                    + (1 - self.rms_prop_cf) * (self.calc_gradient(X, y) ** 2)\n",
        "                )\n",
        "                w_new = self.w - (self.eta * self.calc_gradient(X, y)) / np.sqrt(\n",
        "                    g_new + self.epsilon\n",
        "                )\n",
        "                if (np.abs(w_new - self.w)).mean() < self.tolerance:\n",
        "                    break\n",
        "                self.w = w_new\n",
        "                g = g_new\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception(\"Not trained yet\")\n",
        "        else:\n",
        "            return X @ self.w\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: np.array of shape (d)\n",
        "        \"\"\"\n",
        "        return (2 / X.shape[0]) * (np.array(X.T) @ ((np.array(X) @ self.w) - y)) - (\n",
        "            2 * self.reg_cf * self.w\n",
        "        )\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (l, d)\n",
        "        y: np.array of shape (l)\n",
        "        ---\n",
        "        output: float\n",
        "        \"\"\"\n",
        "        return mean_squared_error(self.predict(X), y)\n"
      ],
      "metadata": {
        "id": "sxhcLOWibl-X"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test on seaborn diamonds' prices dataset**"
      ],
      "metadata": {
        "id": "jaa-11MSU36h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = sns.load_dataset('diamonds')\n",
        "\n",
        "y = data.price\n",
        "X = data.drop(['price'], axis=1)\n",
        "columns = data.drop(['price'], axis=1).columns"
      ],
      "metadata": {
        "id": "GC1kKXDgRmrQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "tjH9pmf_VDw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.replace({\"cut\": {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}}, inplace = True)\n",
        "X.replace({\"color\": {'J': 1, 'I': 2, 'H': 3, 'G': 4, 'F': 5, 'E': 6, 'D': 7}}, inplace = True)\n",
        "X.replace({\"clarity\": {'I1': 1, 'SI2': 2, 'SI1': 3, 'VS2': 4, 'VS1': 5, 'VVS2': 6, 'VVS1': 7, 'IF': 8}}, inplace = True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FZ3sovfERzS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)"
      ],
      "metadata": {
        "id": "4NX6J3zlR7cf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train = pd.DataFrame(X_train_scaled, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_scaled, index=X_test.index)"
      ],
      "metadata": {
        "id": "jM5EIg_XSGND"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_wconst = sm.add_constant(X_train)\n",
        "X_test_wconst = sm.add_constant(X_test)"
      ],
      "metadata": {
        "id": "Q-eg5bCASX03"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default Gradient descent realization:"
      ],
      "metadata": {
        "id": "Hvf2tKBzVGvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gd = LinReg(gd_type='GradientDescent')\n",
        "gd.fit(X_train_wconst, y_train)\n",
        "mean_absolute_error(gd.predict(X_test_wconst), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4Tf7bkSaRC",
        "outputId": "92a3ad60-2135-48a3-ade1-796c98e8036d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "846.6513035125685"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient descent realization:"
      ],
      "metadata": {
        "id": "JzKTVOxyVL29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd = LinReg(max_iter=10000, gd_type='StochasticDescent', delta=0.05)\n",
        "sd.fit(X_train_wconst, y_train)\n",
        "mean_absolute_error(sd.predict(X_test_wconst), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xce8f6MeSk5r",
        "outputId": "ace7261a-462b-4112-86a1-eee09e923772"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "811.4811135181791"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Momentum Gradient descent realization:"
      ],
      "metadata": {
        "id": "by8-O5ArVVlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "momentum = LinReg(gd_type='Momentum', alpha=0.5)\n",
        "momentum.fit(X_train_wconst, y_train)\n",
        "mean_absolute_error(momentum.predict(X_test_wconst), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9_-iIgSmtj",
        "outputId": "7be4acc6-7a80-4559-9049-c0b1587bce43"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "812.9202353028369"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSProp Gradient descent realization:"
      ],
      "metadata": {
        "id": "_C5opEKcVZ32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = LinReg(gd_type='RMSProp', eta=0.1)\n",
        "rmsprop.fit(X_train_wconst, y_train)\n",
        "mean_absolute_error(rmsprop.predict(X_test_wconst), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxpk6A93Rfx_",
        "outputId": "fe85673a-5024-4902-acd0-b2ae1613e920"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "806.9510642812699"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare with default sklearn linreg:"
      ],
      "metadata": {
        "id": "oT0F6kw7VbmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(np.array(X_train_wconst), y_train)\n",
        "mean_absolute_error(model.predict(np.array(X_test_wconst)), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUsunOQ3Sxw3",
        "outputId": "b2647b38-a39c-4833-9ed2-b3555022dc72"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "812.8555360600542"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, my implementation is comparable in quality to sklearn's implementation"
      ],
      "metadata": {
        "id": "WKi2nrLueEX7"
      }
    }
  ]
}