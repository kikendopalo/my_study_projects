{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 17777,
          "databundleVersionId": 869809,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:36.861401Z",
          "iopub.execute_input": "2025-03-19T14:32:36.861714Z",
          "iopub.status.idle": "2025-03-19T14:32:38.219600Z",
          "shell.execute_reply.started": "2025-03-19T14:32:36.861689Z",
          "shell.execute_reply": "2025-03-19T14:32:38.218673Z"
        },
        "id": "rbveQ9jG1Qv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:38.220657Z",
          "iopub.execute_input": "2025-03-19T14:32:38.221093Z",
          "iopub.status.idle": "2025-03-19T14:32:38.562970Z",
          "shell.execute_reply.started": "2025-03-19T14:32:38.221070Z",
          "shell.execute_reply": "2025-03-19T14:32:38.562279Z"
        },
        "id": "Q2gf28m71Qv1",
        "outputId": "722bcee6-dcfb-45f6-a029-b3033f6989be"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:38.564363Z",
          "iopub.execute_input": "2025-03-19T14:32:38.564678Z",
          "iopub.status.idle": "2025-03-19T14:32:45.089596Z",
          "shell.execute_reply.started": "2025-03-19T14:32:38.564648Z",
          "shell.execute_reply": "2025-03-19T14:32:45.088826Z"
        },
        "id": "FXCaIJo41Qv3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy.sparse\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:45.090770Z",
          "iopub.execute_input": "2025-03-19T14:32:45.091238Z",
          "iopub.status.idle": "2025-03-19T14:32:45.094700Z",
          "shell.execute_reply.started": "2025-03-19T14:32:45.091202Z",
          "shell.execute_reply": "2025-03-19T14:32:45.093918Z"
        },
        "id": "VYP7sXeV1Qv3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv', index_col='id')\n",
        "test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv', index_col='id')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:45.095358Z",
          "iopub.execute_input": "2025-03-19T14:32:45.095576Z",
          "iopub.status.idle": "2025-03-19T14:32:45.183841Z",
          "shell.execute_reply.started": "2025-03-19T14:32:45.095556Z",
          "shell.execute_reply": "2025-03-19T14:32:45.183121Z"
        },
        "id": "3xiTx9pN1Qv3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "w1QmPcPb1Qv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:35.012715Z",
          "iopub.execute_input": "2025-03-19T13:22:35.013107Z",
          "iopub.status.idle": "2025-03-19T13:22:35.024445Z",
          "shell.execute_reply.started": "2025-03-19T13:22:35.013071Z",
          "shell.execute_reply": "2025-03-19T13:22:35.023412Z"
        },
        "id": "CVRdNVC01Qv4",
        "outputId": "68fbda99-b11e-45cf-99e6-3aeffcbd398d"
      },
      "outputs": [
        {
          "execution_count": 99,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      keyword location                                               text  \\\nid                                                                          \n1         NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n4         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n5         NaN      NaN  All residents asked to 'shelter in place' are ...   \n6         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n7         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n...       ...      ...                                                ...   \n10869     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n10870     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n10871     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n10872     NaN      NaN  Police investigating after an e-bike collided ...   \n10873     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n\n       target  \nid             \n1           1  \n4           1  \n5           1  \n6           1  \n7           1  \n...       ...  \n10869       1  \n10870       1  \n10871       1  \n10872       1  \n10873       1  \n\n[7613 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10869</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10870</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10871</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10872</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10873</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['target']\n",
        "train.drop('target', axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:45.185034Z",
          "iopub.execute_input": "2025-03-19T14:32:45.185317Z",
          "iopub.status.idle": "2025-03-19T14:32:45.193030Z",
          "shell.execute_reply.started": "2025-03-19T14:32:45.185284Z",
          "shell.execute_reply": "2025-03-19T14:32:45.192241Z"
        },
        "id": "3IAgnnQf1Qv4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check NaN values in all of the columns"
      ],
      "metadata": {
        "id": "Z045GIoV1Qv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isna().mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:36.206688Z",
          "iopub.execute_input": "2025-03-19T13:22:36.207000Z",
          "iopub.status.idle": "2025-03-19T13:22:36.216053Z",
          "shell.execute_reply.started": "2025-03-19T13:22:36.206977Z",
          "shell.execute_reply": "2025-03-19T13:22:36.215015Z"
        },
        "id": "KMvTl6YY1Qv4",
        "outputId": "8f0d4ed5-5061-4a99-9669-a18cea37427f"
      },
      "outputs": [
        {
          "execution_count": 101,
          "output_type": "execute_result",
          "data": {
            "text/plain": "keyword     0.008013\nlocation    0.332720\ntext        0.000000\ndtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train['location'].nunique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:39.542806Z",
          "iopub.execute_input": "2025-03-19T13:22:39.543177Z",
          "iopub.status.idle": "2025-03-19T13:22:39.550110Z",
          "shell.execute_reply.started": "2025-03-19T13:22:39.543146Z",
          "shell.execute_reply": "2025-03-19T13:22:39.549236Z"
        },
        "id": "8ozGZg5a1Qv5",
        "outputId": "60998170-4366-484f-aa39-a034cd461b1c"
      },
      "outputs": [
        {
          "execution_count": 102,
          "output_type": "execute_result",
          "data": {
            "text/plain": "3341"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train['keyword'].nunique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:39.816833Z",
          "iopub.execute_input": "2025-03-19T13:22:39.817150Z",
          "iopub.status.idle": "2025-03-19T13:22:39.823450Z",
          "shell.execute_reply.started": "2025-03-19T13:22:39.817126Z",
          "shell.execute_reply": "2025-03-19T13:22:39.822323Z"
        },
        "id": "tbe-OeDN1Qv5",
        "outputId": "63b0dba1-5504-4607-c857-878e6d3c8990"
      },
      "outputs": [
        {
          "execution_count": 103,
          "output_type": "execute_result",
          "data": {
            "text/plain": "221"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems that the most appropriate way to handle these NaN values is to fill them with empty string, because this data is textual and there many possible values in the dataset"
      ],
      "metadata": {
        "id": "r9_g51To1Qv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.fillna(' ', inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:47.901350Z",
          "iopub.execute_input": "2025-03-19T14:32:47.901702Z",
          "iopub.status.idle": "2025-03-19T14:32:47.908438Z",
          "shell.execute_reply.started": "2025-03-19T14:32:47.901673Z",
          "shell.execute_reply": "2025-03-19T14:32:47.907569Z"
        },
        "id": "vAc13jw31Qv5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test.isna().mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:42.896680Z",
          "iopub.execute_input": "2025-03-19T13:22:42.897026Z",
          "iopub.status.idle": "2025-03-19T13:22:42.904988Z",
          "shell.execute_reply.started": "2025-03-19T13:22:42.896997Z",
          "shell.execute_reply": "2025-03-19T13:22:42.903849Z"
        },
        "id": "KLPmFn_B1Qv5",
        "outputId": "beb2d684-d03d-4299-9cd8-daab7fded828"
      },
      "outputs": [
        {
          "execution_count": 105,
          "output_type": "execute_result",
          "data": {
            "text/plain": "keyword     0.007968\nlocation    0.338645\ntext        0.000000\ndtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test.fillna(' ', inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:32:49.538162Z",
          "iopub.execute_input": "2025-03-19T14:32:49.538473Z",
          "iopub.status.idle": "2025-03-19T14:32:49.544286Z",
          "shell.execute_reply.started": "2025-03-19T14:32:49.538438Z",
          "shell.execute_reply": "2025-03-19T14:32:49.543524Z"
        },
        "id": "wVnZQg3k1Qv5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to tokenize the texts. Since these texts are tweets, i think that we should use TweetTokenizer from nltk"
      ],
      "metadata": {
        "id": "Hn0yNcyt1Qv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's delete stopwords and punctuation that have not so much meaning"
      ],
      "metadata": {
        "id": "dY0OenPv1Qv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(text: str) -> list[str]:\n",
        "    text = tokenize.TweetTokenizer().tokenize(text)\n",
        "    text = [word for word in text if (word.lower() not in stopwords.words('english')) and (word not in punctuation) and (word != '...')]\n",
        "    return text\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:44.704771Z",
          "iopub.execute_input": "2025-03-19T13:22:44.705131Z",
          "iopub.status.idle": "2025-03-19T13:22:44.710009Z",
          "shell.execute_reply.started": "2025-03-19T13:22:44.705101Z",
          "shell.execute_reply": "2025-03-19T13:22:44.708913Z"
        },
        "id": "e9Yhg-rc1Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've decided to try both lemmatization and stemming to choose the best of them."
      ],
      "metadata": {
        "id": "KEsrJNSK1Qv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "stemmer = nltk.stem.snowball.EnglishStemmer()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:45.597963Z",
          "iopub.execute_input": "2025-03-19T13:22:45.598302Z",
          "iopub.status.idle": "2025-03-19T13:22:46.345483Z",
          "shell.execute_reply.started": "2025-03-19T13:22:45.598277Z",
          "shell.execute_reply": "2025-03-19T13:22:46.344477Z"
        },
        "id": "NwNT_NXx1Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_train = train.copy()\n",
        "lemmatized_train['text'] = lemmatized_train['text'].apply(lambda x: \" \".join([i.lemma_ for i in lemmatizer(x)]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:22:48.127513Z",
          "iopub.execute_input": "2025-03-19T13:22:48.127831Z",
          "iopub.status.idle": "2025-03-19T13:23:16.666411Z",
          "shell.execute_reply.started": "2025-03-19T13:22:48.127808Z",
          "shell.execute_reply": "2025-03-19T13:23:16.665561Z"
        },
        "id": "y9l0JdU51Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_test = test.copy()\n",
        "lemmatized_test['text'] = lemmatized_test['text'].apply(lambda x: \" \".join([i.lemma_ for i in lemmatizer(x)]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:23:16.667585Z",
          "iopub.execute_input": "2025-03-19T13:23:16.667911Z",
          "iopub.status.idle": "2025-03-19T13:23:28.368282Z",
          "shell.execute_reply.started": "2025-03-19T13:23:16.667885Z",
          "shell.execute_reply": "2025-03-19T13:23:28.367474Z"
        },
        "id": "zDRaQxKh1Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_train = train.copy()\n",
        "stemmed_train['text'] = stemmed_train['text'].apply(lambda x: ' '.join([stemmer.stem(i) for i in x.split()]))\n",
        "stemmed_test = test.copy()\n",
        "stemmed_test['text'] = stemmed_test['text'].apply(lambda x: ' '.join([stemmer.stem(i) for i in x.split()]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:23:28.369837Z",
          "iopub.execute_input": "2025-03-19T13:23:28.370181Z",
          "iopub.status.idle": "2025-03-19T13:23:30.134650Z",
          "shell.execute_reply.started": "2025-03-19T13:23:28.370146Z",
          "shell.execute_reply": "2025-03-19T13:23:30.133649Z"
        },
        "id": "-xnNulhq1Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think that keyword and location are unique features, so we need to treat them separately from text"
      ],
      "metadata": {
        "id": "GRJgPrcp1Qv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "loc_train = encoder.fit_transform(np.array(train['location']).reshape(-1, 1))\n",
        "loc_test = encoder.transform(np.array(test['location']).reshape(-1, 1))\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "key_train = encoder.fit_transform(np.array(train['keyword']).reshape(-1, 1))\n",
        "key_test = encoder.transform(np.array(test['keyword']).reshape(-1, 1))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:23:30.136193Z",
          "iopub.execute_input": "2025-03-19T13:23:30.136579Z",
          "iopub.status.idle": "2025-03-19T13:23:30.252343Z",
          "shell.execute_reply.started": "2025-03-19T13:23:30.136545Z",
          "shell.execute_reply": "2025-03-19T13:23:30.251534Z"
        },
        "id": "tNukGVZG1Qv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to apply BoW/TF-IDF vectorizers"
      ],
      "metadata": {
        "id": "bumzteNC1Qv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(vectorizer, train, test) -> (pd.Series, pd.Series):\n",
        "    new_train = train.copy()\n",
        "    vectorizer.fit(new_train)\n",
        "    new_train = vectorizer.transform(new_train)\n",
        "    new_test = test.copy()\n",
        "    new_test = vectorizer.transform(new_test)\n",
        "    return new_train, new_test"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:23:30.253156Z",
          "iopub.execute_input": "2025-03-19T13:23:30.253449Z",
          "iopub.status.idle": "2025-03-19T13:23:30.258440Z",
          "shell.execute_reply.started": "2025-03-19T13:23:30.253421Z",
          "shell.execute_reply": "2025-03-19T13:23:30.257339Z"
        },
        "id": "qFkXqyRZ1Qv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bow_lemm_train, bow_lemm_test = vectorize(CountVectorizer(tokenizer=my_tokenizer), lemmatized_train['text'], lemmatized_test['text'])\n",
        "bow_stem_train, bow_stem_test = vectorize(CountVectorizer(tokenizer=my_tokenizer), stemmed_train['text'], stemmed_test['text'])\n",
        "tfidf_lemm_train, tfidf_lemm_test = vectorize(TfidfVectorizer(tokenizer=my_tokenizer), lemmatized_train['text'], lemmatized_test['text'])\n",
        "tfidf_stem_train, tfidf_stem_test = vectorize(TfidfVectorizer(tokenizer=my_tokenizer), stemmed_train['text'], stemmed_test['text'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:23:30.259397Z",
          "iopub.execute_input": "2025-03-19T13:23:30.259717Z",
          "iopub.status.idle": "2025-03-19T13:26:14.786143Z",
          "shell.execute_reply.started": "2025-03-19T13:23:30.259688Z",
          "shell.execute_reply": "2025-03-19T13:26:14.785326Z"
        },
        "id": "EqR-hUtT1Qv7",
        "outputId": "cd08ae79-824f-41dd-950f-9432209762e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's join bow and tfidf interpretations with one-hot encoded locations and keywords into whole sparse matriсes"
      ],
      "metadata": {
        "id": "fCyyg8QI1Qv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_lemm_train = scipy.sparse.csr_matrix(pd.DataFrame(loc_train,index=train.index).join(pd.DataFrame(key_train,index=train.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(bow_lemm_train, index=train.index), rsuffix='text'))\n",
        "tfidf_lemm_train = scipy.sparse.csr_matrix(pd.DataFrame(loc_train,index=train.index).join(pd.DataFrame(key_train,index=train.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(tfidf_lemm_train, index=train.index), rsuffix='text'))\n",
        "bow_stem_train = scipy.sparse.csr_matrix(pd.DataFrame(loc_train,index=train.index).join(pd.DataFrame(key_train,index=train.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(bow_stem_train, index=train.index), rsuffix='text'))\n",
        "tfidf_stem_train = scipy.sparse.csr_matrix(pd.DataFrame(loc_train,index=train.index).join(pd.DataFrame(key_train,index=train.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(tfidf_stem_train, index=train.index), rsuffix='text'))\n",
        "bow_lemm_test = scipy.sparse.csr_matrix(pd.DataFrame(loc_test,index=test.index).join(pd.DataFrame(key_test,index=test.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(bow_lemm_test, index=test.index), rsuffix='text'))\n",
        "tfidf_lemm_test = scipy.sparse.csr_matrix(pd.DataFrame(loc_test,index=test.index).join(pd.DataFrame(key_test,index=test.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(tfidf_lemm_test, index=test.index), rsuffix='text'))\n",
        "bow_stem_test = scipy.sparse.csr_matrix(pd.DataFrame(loc_test,index=test.index).join(pd.DataFrame(key_test,index=test.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(bow_stem_test, index=test.index), rsuffix='text'))\n",
        "tfidf_stem_test = scipy.sparse.csr_matrix(pd.DataFrame(loc_test,index=test.index).join(pd.DataFrame(key_test,index=test.index), rsuffix='key', lsuffix='loc').join(pd.DataFrame.sparse.from_spmatrix(tfidf_stem_test, index=test.index), rsuffix='text'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:26:14.787090Z",
          "iopub.execute_input": "2025-03-19T13:26:14.787463Z",
          "iopub.status.idle": "2025-03-19T13:27:08.250226Z",
          "shell.execute_reply.started": "2025-03-19T13:26:14.787428Z",
          "shell.execute_reply": "2025-03-19T13:27:08.249454Z"
        },
        "id": "wFThDa-L1Qv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training ML models**"
      ],
      "metadata": {
        "id": "E2vl6lyQ1Qv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:33:32.906032Z",
          "iopub.execute_input": "2025-03-19T14:33:32.906356Z",
          "iopub.status.idle": "2025-03-19T14:33:33.128745Z",
          "shell.execute_reply.started": "2025-03-19T14:33:32.906328Z",
          "shell.execute_reply": "2025-03-19T14:33:33.127840Z"
        },
        "id": "QYHcTcHq1Qv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:33:35.970536Z",
          "iopub.execute_input": "2025-03-19T14:33:35.970865Z",
          "iopub.status.idle": "2025-03-19T14:33:35.974810Z",
          "shell.execute_reply.started": "2025-03-19T14:33:35.970837Z",
          "shell.execute_reply": "2025-03-19T14:33:35.973822Z"
        },
        "id": "mKHPMbfl1Qv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_training(train, y):\n",
        "\n",
        "    models = [\n",
        "        LogisticRegression(),\n",
        "        SVC(),\n",
        "        KNeighborsClassifier(),\n",
        "        DecisionTreeClassifier(),\n",
        "        RandomForestClassifier(),\n",
        "        GradientBoostingClassifier()\n",
        "    ]\n",
        "\n",
        "    param_grids = [\n",
        "        {\n",
        "            'penalty': ['l1', 'l2'],\n",
        "            'C': np.logspace(-3,0,10),\n",
        "            'class_weight': [None, 'balanced'],\n",
        "            'solver': ['saga']\n",
        "        },\n",
        "        {\n",
        "            'C': np.logspace(-3,0,10),\n",
        "            'class_weight': [None, 'balanced'],\n",
        "            'kernel': ['linear', 'rbf']\n",
        "        },\n",
        "        {\n",
        "            'n_neighbors': np.arange(1, 26)\n",
        "        },\n",
        "        {\n",
        "            'class_weight': [None, 'balanced'],\n",
        "            'min_samples_split': np.arange(2, 103, 10),\n",
        "            'min_samples_leaf': np.arange(1, 102, 10)\n",
        "        },\n",
        "        {\n",
        "            'n_estimators': [50, 100],\n",
        "            'class_weight': [None, 'balanced'],\n",
        "            'min_samples_split': np.arange(2, 53, 10),\n",
        "            'min_samples_leaf': np.arange(1, 52, 10)\n",
        "        },\n",
        "        {\n",
        "            'n_estimators': [100],\n",
        "            'min_samples_split': np.arange(2, 53, 10),\n",
        "            'min_samples_leaf': np.arange(1, 52, 10)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.3, stratify=y)\n",
        "    grid_models = []\n",
        "\n",
        "    for model, params in zip(models, param_grids):\n",
        "        grid = GridSearchCV(model, params, scoring='f1', cv=5, n_jobs=-1)\n",
        "        grid.fit(X_train, y_train)\n",
        "        grid_models.append((grid.best_estimator_, f1_score(grid.best_estimator_.fit(X_train, y_train).predict(X_test), y_test), grid.best_params_))\n",
        "        print(f'{model} trained {datetime.datetime.now()}')\n",
        "\n",
        "    return max(grid_models, key=lambda x: x[1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:27:08.257883Z",
          "iopub.execute_input": "2025-03-19T13:27:08.258181Z",
          "iopub.status.idle": "2025-03-19T13:27:08.275415Z",
          "shell.execute_reply.started": "2025-03-19T13:27:08.258159Z",
          "shell.execute_reply": "2025-03-19T13:27:08.274485Z"
        },
        "id": "QnprZ5Em1Qv8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "grid_training(bow_lemm_train, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T10:09:29.533687Z",
          "iopub.execute_input": "2025-03-19T10:09:29.534132Z",
          "iopub.status.idle": "2025-03-19T10:50:40.948656Z",
          "shell.execute_reply.started": "2025-03-19T10:09:29.534061Z",
          "shell.execute_reply": "2025-03-19T10:50:40.947422Z"
        },
        "id": "g_qidfih1Qv8",
        "outputId": "5249801d-80b6-4456-de45-a6d963c96d65"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "LogisticRegression() trained 2025-03-19 10:09:55.693728\nSVC() trained 2025-03-19 10:13:35.104555\nKNeighborsClassifier() trained 2025-03-19 10:13:45.935171\nDecisionTreeClassifier() trained 2025-03-19 10:16:34.506596\nRandomForestClassifier() trained 2025-03-19 10:26:20.042457\nGradientBoostingClassifier() trained 2025-03-19 10:50:40.940162\n",
          "output_type": "stream"
        },
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(LogisticRegression(C=0.21544346900318823, class_weight='balanced',\n                    solver='saga'),\n 0.7603565810173046,\n {'C': 0.21544346900318823,\n  'class_weight': 'balanced',\n  'penalty': 'l2',\n  'solver': 'saga'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "grid_training(bow_stem_train, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T11:17:15.705662Z",
          "iopub.execute_input": "2025-03-19T11:17:15.705975Z",
          "iopub.status.idle": "2025-03-19T11:50:29.064839Z",
          "shell.execute_reply.started": "2025-03-19T11:17:15.705953Z",
          "shell.execute_reply": "2025-03-19T11:50:29.063884Z"
        },
        "id": "zP8EQN8X1Qv8",
        "outputId": "38a5c622-8585-4f16-8385-3e0191c6caf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "LogisticRegression() trained 2025-03-19 11:17:41.405483\nSVC() trained 2025-03-19 11:21:17.695963\nKNeighborsClassifier() trained 2025-03-19 11:21:27.445845\nDecisionTreeClassifier() trained 2025-03-19 11:24:15.806724\nRandomForestClassifier() trained 2025-03-19 11:33:59.406270\nGradientBoostingClassifier() trained 2025-03-19 11:50:29.056969\n",
          "output_type": "stream"
        },
        {
          "execution_count": 58,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(LogisticRegression(C=0.1, class_weight='balanced', solver='saga'),\n 0.7552966101694917,\n {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "grid_training(tfidf_lemm_train, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T11:50:29.066200Z",
          "iopub.execute_input": "2025-03-19T11:50:29.066501Z",
          "iopub.status.idle": "2025-03-19T12:24:37.796504Z",
          "shell.execute_reply.started": "2025-03-19T11:50:29.066477Z",
          "shell.execute_reply": "2025-03-19T12:24:37.795641Z"
        },
        "id": "oUdGpskU1Qv8",
        "outputId": "ede1f50d-ab1c-403c-d64c-7c7dc60420d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "LogisticRegression() trained 2025-03-19 11:50:36.050765\nSVC() trained 2025-03-19 11:54:15.946875\nKNeighborsClassifier() trained 2025-03-19 11:55:21.199317\nDecisionTreeClassifier() trained 2025-03-19 11:58:33.306595\nRandomForestClassifier() trained 2025-03-19 12:08:09.122116\nGradientBoostingClassifier() trained 2025-03-19 12:24:37.790521\n",
          "output_type": "stream"
        },
        {
          "execution_count": 59,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(SVC(class_weight='balanced', kernel='linear'),\n 0.7489583333333332,\n {'C': 1.0, 'class_weight': 'balanced', 'kernel': 'linear'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "grid_training(tfidf_stem_train, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T12:24:37.798006Z",
          "iopub.execute_input": "2025-03-19T12:24:37.798303Z",
          "iopub.status.idle": "2025-03-19T12:59:43.098907Z",
          "shell.execute_reply.started": "2025-03-19T12:24:37.798271Z",
          "shell.execute_reply": "2025-03-19T12:59:43.098037Z"
        },
        "id": "1CXIYkuK1Qv8",
        "outputId": "5be19340-4f09-4bd3-8991-4144c0804d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "LogisticRegression() trained 2025-03-19 12:24:44.950499\nSVC() trained 2025-03-19 12:28:25.593721\nKNeighborsClassifier() trained 2025-03-19 12:29:30.899361\nDecisionTreeClassifier() trained 2025-03-19 12:32:42.953745\nRandomForestClassifier() trained 2025-03-19 12:42:36.832598\nGradientBoostingClassifier() trained 2025-03-19 12:59:43.092958\n",
          "output_type": "stream"
        },
        {
          "execution_count": 60,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(LogisticRegression(class_weight='balanced', solver='saga'),\n 0.7387480600103465,\n {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems that using bag of words with lemmatization is the best approach. The best model that we got was LogisticRegression(). Let's train the best model on the whole train dataset and submit predictions for the test dataset."
      ],
      "metadata": {
        "id": "I0_Y42mB1Qv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = LogisticRegression(C=0.21544346900318823, class_weight='balanced', penalty='l2', solver='saga', random_state=1)\n",
        "best_model.fit(bow_lemm_train, y)\n",
        "pd.DataFrame(best_model.predict(bow_lemm_test), index=test.index, columns=['target']).to_csv('/kaggle/working/output.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T13:32:04.729954Z",
          "iopub.execute_input": "2025-03-19T13:32:04.730354Z",
          "iopub.status.idle": "2025-03-19T13:32:05.054887Z",
          "shell.execute_reply.started": "2025-03-19T13:32:04.730320Z",
          "shell.execute_reply": "2025-03-19T13:32:05.053781Z"
        },
        "id": "mgbv2Nw91Qv9",
        "outputId": "2c8ba795-358b-4164-fcf7-903cd1064a96"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F1-score on submitted predictions = Score: 0.79773**"
      ],
      "metadata": {
        "id": "68xXKro91Qv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network from scratch**"
      ],
      "metadata": {
        "id": "Svy17-te1Qv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout, GRU, SimpleRNN\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:05:07.270424Z",
          "iopub.execute_input": "2025-03-19T15:05:07.270776Z",
          "iopub.status.idle": "2025-03-19T15:05:07.275436Z",
          "shell.execute_reply.started": "2025-03-19T15:05:07.270738Z",
          "shell.execute_reply": "2025-03-19T15:05:07.274446Z"
        },
        "id": "tgQprCb_1Qv9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've chosen CNN because it states that \"A CNN usually performs just as well as an RNN on text-classification tasks and trains much faster.\" in the next internet articles: https://www.atmosera.com/blog/text-classification-with-neural-networks/  and  https://www.geeksforgeeks.org/text-classification-using-cnn/."
      ],
      "metadata": {
        "id": "8s6V6DUs1Qv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea is taken from https://www.atmosera.com/blog/text-classification-with-neural-networks/."
      ],
      "metadata": {
        "id": "DduOi-zY1Qv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.3, stratify=y, random_state=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:33:45.862612Z",
          "iopub.execute_input": "2025-03-19T14:33:45.862901Z",
          "iopub.status.idle": "2025-03-19T14:33:45.874914Z",
          "shell.execute_reply.started": "2025-03-19T14:33:45.862880Z",
          "shell.execute_reply": "2025-03-19T14:33:45.874040Z"
        },
        "id": "F6ixC46D1Qv9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=25000)\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "sequences = tokenizer.texts_to_sequences(X_train['text'] + X_train['location'] + X_train['keyword'])\n",
        "train_emb = pad_sequences(sequences, maxlen=500)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test['text'] + X_test['location'] + X_test['keyword'])\n",
        "test_emb = pad_sequences(test_sequences, maxlen=500)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:33:46.259959Z",
          "iopub.execute_input": "2025-03-19T14:33:46.260289Z",
          "iopub.status.idle": "2025-03-19T14:33:46.576597Z",
          "shell.execute_reply.started": "2025-03-19T14:33:46.260260Z",
          "shell.execute_reply": "2025-03-19T14:33:46.575599Z"
        },
        "id": "ZcN1uwJU1Qv9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "networks_cnn = []\n",
        "\n",
        "for emb in [16, 32, 64, 128, 256]:\n",
        "    for maxpooling in [2, 3]:\n",
        "        for dropout in [0.1, 0.2, 0.3, 0.4]:\n",
        "            for batch in [20, 50, 100]:\n",
        "\n",
        "                model = Sequential()\n",
        "                model.add(Embedding(25000, emb, input_length=500))\n",
        "                model.add(Conv1D(32, 7, activation='relu'))\n",
        "                model.add(MaxPooling1D(maxpooling))\n",
        "                model.add(Conv1D(32, 7, activation='relu'))\n",
        "                model.add(GlobalMaxPooling1D())\n",
        "                model.add(Dropout(dropout))\n",
        "                model.add(Dense(1, activation='sigmoid'))\n",
        "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['f1_score'])\n",
        "                model.fit(train_emb, y_train, validation_split=0.2, epochs=10, batch_size=batch)\n",
        "                networks_cnn.append(((emb, maxpooling, dropout, batch), model, f1_score(np.round(model.predict(test_emb)).reshape(y_test.shape), y_test)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ar6dwGJI1Qv-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max(networks_cnn, key=lambda x: x[2])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T14:59:35.231715Z",
          "iopub.execute_input": "2025-03-19T14:59:35.232036Z",
          "iopub.status.idle": "2025-03-19T14:59:35.237424Z",
          "shell.execute_reply.started": "2025-03-19T14:59:35.232007Z",
          "shell.execute_reply": "2025-03-19T14:59:35.236578Z"
        },
        "id": "Um2uUvIZ1Qv-",
        "outputId": "f61a0fa7-0915-4de1-872e-54716183867e"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((128, 2, 0.3, 100),\n <Sequential name=sequential_80, built=True>,\n 0.731457800511509)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(25000, output_dim=64))\n",
        "model.add(GRU(256, return_sequences=True))\n",
        "model.add(SimpleRNN(128))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['f1_score'])\n",
        "model.fit(train_emb, y_train, validation_split=0.2, epochs=10, batch_size=100)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:11:26.104031Z",
          "iopub.execute_input": "2025-03-19T15:11:26.104320Z",
          "iopub.status.idle": "2025-03-19T15:14:59.725822Z",
          "shell.execute_reply.started": "2025-03-19T15:11:26.104298Z",
          "shell.execute_reply": "2025-03-19T15:14:59.725017Z"
        },
        "id": "CLsCPS6R1Qv-",
        "outputId": "573aa7aa-35b3-4515-a659-9c91ee00425c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 500ms/step - f1_score: 0.5946 - loss: 0.6766 - val_f1_score: 0.5890 - val_loss: 0.5616\nEpoch 2/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 491ms/step - f1_score: 0.6055 - loss: 0.4594 - val_f1_score: 0.5890 - val_loss: 0.5021\nEpoch 3/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 488ms/step - f1_score: 0.6042 - loss: 0.2991 - val_f1_score: 0.5890 - val_loss: 0.5668\nEpoch 4/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 490ms/step - f1_score: 0.6106 - loss: 0.1028 - val_f1_score: 0.5890 - val_loss: 0.7299\nEpoch 5/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 491ms/step - f1_score: 0.6103 - loss: 0.0602 - val_f1_score: 0.5890 - val_loss: 0.8772\nEpoch 6/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 489ms/step - f1_score: 0.5923 - loss: 0.0379 - val_f1_score: 0.5890 - val_loss: 0.9439\nEpoch 7/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 491ms/step - f1_score: 0.6162 - loss: 0.0168 - val_f1_score: 0.5890 - val_loss: 0.9521\nEpoch 8/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 492ms/step - f1_score: 0.6116 - loss: 0.0177 - val_f1_score: 0.5890 - val_loss: 0.9517\nEpoch 9/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 488ms/step - f1_score: 0.5951 - loss: 0.0120 - val_f1_score: 0.5890 - val_loss: 0.9963\nEpoch 10/10\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 489ms/step - f1_score: 0.6031 - loss: 0.0172 - val_f1_score: 0.5890 - val_loss: 1.0497\n",
          "output_type": "stream"
        },
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x797f6b79ead0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'random rnn score: {f1_score(np.round(model.predict(test_emb)).reshape(y_test.shape), y_test)} | min cnn score: {min(networks_cnn, key=lambda x: x[2])[2]}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:17:42.830373Z",
          "iopub.execute_input": "2025-03-19T15:17:42.830678Z",
          "iopub.status.idle": "2025-03-19T15:17:54.858213Z",
          "shell.execute_reply.started": "2025-03-19T15:17:42.830655Z",
          "shell.execute_reply": "2025-03-19T15:17:54.857314Z"
        },
        "id": "R9KCKQql1Qv-",
        "outputId": "97b319a8-e38a-4c33-ee7e-e38dfdbe3aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 166ms/step\nrandom rnn score: 0.6594161419576416 | min cnn score: 0.6839145106861643\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, RNN takes much longer to train, but score of RNN with random values of hyperparameters is worse than minimal score that we achieved with CNN, so i decided to use the best CNN for submission predictions (according to statistics)"
      ],
      "metadata": {
        "id": "htTxNSGr1Qv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=25000)\n",
        "tokenizer.fit_on_texts(train['text'])\n",
        "sequences = tokenizer.texts_to_sequences(train['text'] + train['location'] + train['keyword'])\n",
        "train_emb = pad_sequences(sequences, maxlen=500)\n",
        "test_sequences = tokenizer.texts_to_sequences(test['text'] + test['location'] + test['keyword'])\n",
        "test_emb = pad_sequences(test_sequences, maxlen=500)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:23:11.593293Z",
          "iopub.execute_input": "2025-03-19T15:23:11.593660Z",
          "iopub.status.idle": "2025-03-19T15:23:11.947640Z",
          "shell.execute_reply.started": "2025-03-19T15:23:11.593631Z",
          "shell.execute_reply": "2025-03-19T15:23:11.946722Z"
        },
        "id": "4BPuYX0Q1Qv-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = Sequential()\n",
        "best_model.add(Embedding(25000, 128, input_length=500))\n",
        "best_model.add(Conv1D(32, 7, activation='relu'))\n",
        "best_model.add(MaxPooling1D(2))\n",
        "best_model.add(Conv1D(32, 7, activation='relu'))\n",
        "best_model.add(GlobalMaxPooling1D())\n",
        "best_model.add(Dropout(0.3))\n",
        "best_model.add(Dense(1, activation='sigmoid'))\n",
        "best_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['f1_score'])\n",
        "best_model.fit(train_emb, y, validation_split=0.2, epochs=10, batch_size=100)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:23:57.406616Z",
          "iopub.execute_input": "2025-03-19T15:23:57.406995Z",
          "iopub.status.idle": "2025-03-19T15:24:15.755595Z",
          "shell.execute_reply.started": "2025-03-19T15:23:57.406960Z",
          "shell.execute_reply": "2025-03-19T15:24:15.754875Z"
        },
        "id": "Z4BEYLop1Qv-",
        "outputId": "a80f36b2-902c-4aef-dd6e-529c28e2cee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - f1_score: 0.5921 - loss: 0.6738 - val_f1_score: 0.6353 - val_loss: 0.5636\nEpoch 2/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 0.5856 - loss: 0.4239 - val_f1_score: 0.6353 - val_loss: 0.4596\nEpoch 3/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 0.5849 - loss: 0.2090 - val_f1_score: 0.6353 - val_loss: 0.5168\nEpoch 4/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 0.5905 - loss: 0.1391 - val_f1_score: 0.6353 - val_loss: 0.6224\nEpoch 5/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 0.5969 - loss: 0.0683 - val_f1_score: 0.6353 - val_loss: 0.6702\nEpoch 6/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 0.5930 - loss: 0.0450 - val_f1_score: 0.6353 - val_loss: 0.7575\nEpoch 7/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 0.5906 - loss: 0.0405 - val_f1_score: 0.6353 - val_loss: 0.8409\nEpoch 8/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 0.5884 - loss: 0.0275 - val_f1_score: 0.6353 - val_loss: 0.8847\nEpoch 9/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 0.5935 - loss: 0.0203 - val_f1_score: 0.6353 - val_loss: 0.9494\nEpoch 10/10\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 0.5927 - loss: 0.0224 - val_f1_score: 0.6353 - val_loss: 1.1459\n",
          "output_type": "stream"
        },
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x797f96845630>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(np.round(best_model.predict(test_emb)).reshape(test.shape[0]).astype('int'), index=test.index, columns=['target']).to_csv('/kaggle/working/nn_output.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:28:08.286214Z",
          "iopub.execute_input": "2025-03-19T15:28:08.286550Z",
          "iopub.status.idle": "2025-03-19T15:28:08.521053Z",
          "shell.execute_reply.started": "2025-03-19T15:28:08.286526Z",
          "shell.execute_reply": "2025-03-19T15:28:08.520180Z"
        },
        "id": "n25y1MzS1Qv_",
        "outputId": "8e619e86-8c01-4734-acb4-20375a0f1c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F1-score on submitted predictions = Score: 0.73460**"
      ],
      "metadata": {
        "id": "VaRKZfWr1Qv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-tuning pre-trained model**"
      ],
      "metadata": {
        "id": "DKOQwdq51Qv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate accelerate"
      ],
      "metadata": {
        "trusted": true,
        "id": "e_o7rGIp1Qv_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "import evaluate\n",
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "import datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:18:33.234130Z",
          "iopub.execute_input": "2025-03-19T17:18:33.234452Z",
          "iopub.status.idle": "2025-03-19T17:18:33.238937Z",
          "shell.execute_reply.started": "2025-03-19T17:18:33.234428Z",
          "shell.execute_reply": "2025-03-19T17:18:33.238044Z"
        },
        "id": "jPW9F6q81Qv_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've decided to choose DistilBERT. The idea is taken from https://huggingface.co/docs/transformers/en/tasks/sequence_classification"
      ],
      "metadata": {
        "id": "U1hzXGe_1Qv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts using the BERT base model."
      ],
      "metadata": {
        "id": "Jo5-kHcC1Qv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train, y, test_size=0.3, stratify=y, random_state=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:21.214588Z",
          "iopub.execute_input": "2025-03-19T17:35:21.214878Z",
          "iopub.status.idle": "2025-03-19T17:35:21.224695Z",
          "shell.execute_reply.started": "2025-03-19T17:35:21.214858Z",
          "shell.execute_reply": "2025-03-19T17:35:21.223772Z"
        },
        "id": "uGJJh7yT1Qv_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:21.955483Z",
          "iopub.execute_input": "2025-03-19T17:35:21.955929Z",
          "iopub.status.idle": "2025-03-19T17:35:22.095917Z",
          "shell.execute_reply.started": "2025-03-19T17:35:21.955897Z",
          "shell.execute_reply": "2025-03-19T17:35:22.095247Z"
        },
        "id": "tBciz2oM1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(pd.DataFrame(pd.DataFrame(X_train['text'] + X_train['location'] + X_train['keyword']).join(y_train)).rename({0:'text', 'target':'label'}, axis=1))\n",
        "val_dataset = Dataset.from_pandas(pd.DataFrame(pd.DataFrame(X_val['text'] + X_val['location'] + X_val['keyword']).join(y_val)).rename({0:'text', 'target':'label'}, axis=1))\n",
        "dataset = DatasetDict()\n",
        "\n",
        "dataset['train'] = train_dataset\n",
        "dataset['validation'] = val_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:22.749757Z",
          "iopub.execute_input": "2025-03-19T17:35:22.750188Z",
          "iopub.status.idle": "2025-03-19T17:35:22.783874Z",
          "shell.execute_reply.started": "2025-03-19T17:35:22.750144Z",
          "shell.execute_reply": "2025-03-19T17:35:22.783121Z"
        },
        "id": "svcJt7Na1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(df):\n",
        "    return tokenizer(df['text'], truncation=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:27.760118Z",
          "iopub.execute_input": "2025-03-19T17:35:27.760399Z",
          "iopub.status.idle": "2025-03-19T17:35:27.764932Z",
          "shell.execute_reply.started": "2025-03-19T17:35:27.760380Z",
          "shell.execute_reply": "2025-03-19T17:35:27.763689Z"
        },
        "id": "AHtb0I6J1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:29.074389Z",
          "iopub.execute_input": "2025-03-19T17:35:29.074704Z",
          "iopub.status.idle": "2025-03-19T17:35:29.622019Z",
          "shell.execute_reply.started": "2025-03-19T17:35:29.074679Z",
          "shell.execute_reply": "2025-03-19T17:35:29.621036Z"
        },
        "colab": {
          "referenced_widgets": [
            "590564eff14a454cb34ae4007d16ec69",
            "8ddf65c37e1e412c8dd215dbea68d101"
          ]
        },
        "id": "wC7x3Snz1QwA",
        "outputId": "501527d9-b2f4-453c-d6d4-7ceb7908ed3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5329 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "590564eff14a454cb34ae4007d16ec69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2284 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ddf65c37e1e412c8dd215dbea68d101"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:30.558672Z",
          "iopub.execute_input": "2025-03-19T17:35:30.558984Z",
          "iopub.status.idle": "2025-03-19T17:35:30.562847Z",
          "shell.execute_reply.started": "2025-03-19T17:35:30.558959Z",
          "shell.execute_reply": "2025-03-19T17:35:30.561986Z"
        },
        "id": "d8oXkD_Z1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = evaluate.load(\"f1\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:31.443253Z",
          "iopub.execute_input": "2025-03-19T17:35:31.443588Z",
          "iopub.status.idle": "2025-03-19T17:35:31.710697Z",
          "shell.execute_reply.started": "2025-03-19T17:35:31.443559Z",
          "shell.execute_reply": "2025-03-19T17:35:31.709990Z"
        },
        "id": "RqfNs0HT1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f_score.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:32.681672Z",
          "iopub.execute_input": "2025-03-19T17:35:32.681987Z",
          "iopub.status.idle": "2025-03-19T17:35:32.686087Z",
          "shell.execute_reply.started": "2025-03-19T17:35:32.681963Z",
          "shell.execute_reply": "2025-03-19T17:35:32.685267Z"
        },
        "id": "iMGuVRO01QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(tokenized_data[\"train\"]) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:33.650352Z",
          "iopub.execute_input": "2025-03-19T17:35:33.650683Z",
          "iopub.status.idle": "2025-03-19T17:35:33.658985Z",
          "shell.execute_reply.started": "2025-03-19T17:35:33.650656Z",
          "shell.execute_reply": "2025-03-19T17:35:33.658092Z"
        },
        "id": "AKBN2q3R1QwA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:00:02.737765Z",
          "iopub.execute_input": "2025-03-19T17:00:02.738100Z",
          "iopub.status.idle": "2025-03-19T17:00:03.548469Z",
          "shell.execute_reply.started": "2025-03-19T17:00:02.738071Z",
          "shell.execute_reply": "2025-03-19T17:00:03.547855Z"
        },
        "id": "sJoscNTt1QwB",
        "outputId": "a82e74c4-54d4-4228-d358-d833a18c0067"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_data['train'],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:42.325207Z",
          "iopub.execute_input": "2025-03-19T17:35:42.325567Z",
          "iopub.status.idle": "2025-03-19T17:35:42.405139Z",
          "shell.execute_reply.started": "2025-03-19T17:35:42.325530Z",
          "shell.execute_reply": "2025-03-19T17:35:42.404415Z"
        },
        "id": "C1yabjDL1QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_data['validation'],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:35:43.170176Z",
          "iopub.execute_input": "2025-03-19T17:35:43.170464Z",
          "iopub.status.idle": "2025-03-19T17:35:43.229742Z",
          "shell.execute_reply.started": "2025-03-19T17:35:43.170442Z",
          "shell.execute_reply": "2025-03-19T17:35:43.229058Z"
        },
        "id": "d973nB4O1QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:00:06.979067Z",
          "iopub.execute_input": "2025-03-19T17:00:06.979489Z",
          "iopub.status.idle": "2025-03-19T17:00:06.991057Z",
          "shell.execute_reply.started": "2025-03-19T17:00:06.979452Z",
          "shell.execute_reply": "2025-03-19T17:00:06.990140Z"
        },
        "id": "-NaxOZpx1QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:00:08.590896Z",
          "iopub.execute_input": "2025-03-19T17:00:08.591187Z",
          "iopub.status.idle": "2025-03-19T17:00:08.595324Z",
          "shell.execute_reply.started": "2025-03-19T17:00:08.591165Z",
          "shell.execute_reply": "2025-03-19T17:00:08.594465Z"
        },
        "id": "YelL7HqV1QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [metric_callback]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:01:37.544143Z",
          "iopub.execute_input": "2025-03-19T17:01:37.544433Z",
          "iopub.status.idle": "2025-03-19T17:01:37.548366Z",
          "shell.execute_reply.started": "2025-03-19T17:01:37.544411Z",
          "shell.execute_reply": "2025-03-19T17:01:37.547423Z"
        },
        "id": "na3PeVV21QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=10, callbacks=callbacks)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:01:58.746627Z",
          "iopub.execute_input": "2025-03-19T17:01:58.746935Z",
          "iopub.status.idle": "2025-03-19T17:10:42.251157Z",
          "shell.execute_reply.started": "2025-03-19T17:01:58.746910Z",
          "shell.execute_reply": "2025-03-19T17:10:42.250155Z"
        },
        "id": "y2U4Md7T1QwB",
        "outputId": "3f8589bc-85bb-424c-88a8-c82718140208"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n333/333 [==============================] - 58s 174ms/step - loss: 0.3343 - val_loss: 0.4181 - f1: 0.7482\nEpoch 2/10\n333/333 [==============================] - 52s 155ms/step - loss: 0.2485 - val_loss: 0.4265 - f1: 0.7641\nEpoch 3/10\n333/333 [==============================] - 52s 155ms/step - loss: 0.1892 - val_loss: 0.5163 - f1: 0.7891\nEpoch 4/10\n333/333 [==============================] - 51s 155ms/step - loss: 0.1545 - val_loss: 0.5354 - f1: 0.7840\nEpoch 5/10\n333/333 [==============================] - 52s 156ms/step - loss: 0.1347 - val_loss: 0.5254 - f1: 0.7849\nEpoch 6/10\n333/333 [==============================] - 52s 156ms/step - loss: 0.1328 - val_loss: 0.5254 - f1: 0.7849\nEpoch 7/10\n333/333 [==============================] - 52s 155ms/step - loss: 0.1377 - val_loss: 0.5254 - f1: 0.7849\nEpoch 8/10\n333/333 [==============================] - 52s 156ms/step - loss: 0.1315 - val_loss: 0.5254 - f1: 0.7849\nEpoch 9/10\n333/333 [==============================] - 52s 155ms/step - loss: 0.1330 - val_loss: 0.5254 - f1: 0.7849\nEpoch 10/10\n333/333 [==============================] - 52s 155ms/step - loss: 0.1344 - val_loss: 0.5254 - f1: 0.7849\n",
          "output_type": "stream"
        },
        {
          "execution_count": 291,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf_keras.src.callbacks.History at 0x797cc7957f40>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset.from_pandas(pd.DataFrame(pd.DataFrame(test['text'] + test['location'] + test['keyword'])).rename({0:'text'}, axis=1))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:38:42.070784Z",
          "iopub.execute_input": "2025-03-19T17:38:42.071116Z",
          "iopub.status.idle": "2025-03-19T17:38:42.084948Z",
          "shell.execute_reply.started": "2025-03-19T17:38:42.071087Z",
          "shell.execute_reply": "2025-03-19T17:38:42.084261Z"
        },
        "id": "Q0VHxONT1QwB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:40:32.037243Z",
          "iopub.execute_input": "2025-03-19T17:40:32.037586Z",
          "iopub.status.idle": "2025-03-19T17:40:32.278605Z",
          "shell.execute_reply.started": "2025-03-19T17:40:32.037560Z",
          "shell.execute_reply": "2025-03-19T17:40:32.277618Z"
        },
        "colab": {
          "referenced_widgets": [
            "55affa9ccddf4db2b0fb586262148db6"
          ]
        },
        "id": "bNuRLqF91QwB",
        "outputId": "c213f5bc-0a55-4f26-c734-7aa80428ee19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3263 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55affa9ccddf4db2b0fb586262148db6"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    tokenized_test,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:40:40.610823Z",
          "iopub.execute_input": "2025-03-19T17:40:40.611096Z",
          "iopub.status.idle": "2025-03-19T17:40:40.664490Z",
          "shell.execute_reply.started": "2025-03-19T17:40:40.611076Z",
          "shell.execute_reply": "2025-03-19T17:40:40.663896Z"
        },
        "id": "rJ-P_kUU1QwC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.predict(tf_test_set).logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:40:48.435898Z",
          "iopub.execute_input": "2025-03-19T17:40:48.436207Z",
          "iopub.status.idle": "2025-03-19T17:40:58.476386Z",
          "shell.execute_reply.started": "2025-03-19T17:40:48.436185Z",
          "shell.execute_reply": "2025-03-19T17:40:58.475689Z"
        },
        "id": "btcNfDhD1QwC",
        "outputId": "4898d89f-2c47-4bb1-b186-c271cb73c250"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "204/204 [==============================] - 10s 42ms/step\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tf.nn.softmax(logits, axis=-1)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:41:02.404898Z",
          "iopub.execute_input": "2025-03-19T17:41:02.405185Z",
          "iopub.status.idle": "2025-03-19T17:41:02.410145Z",
          "shell.execute_reply.started": "2025-03-19T17:41:02.405162Z",
          "shell.execute_reply": "2025-03-19T17:41:02.409235Z"
        },
        "id": "jK14h9Fi1QwC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predicted_labels, index=test.index, columns=['target']).to_csv('/kaggle/working/distilbert_output.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T17:41:47.713116Z",
          "iopub.execute_input": "2025-03-19T17:41:47.713435Z",
          "iopub.status.idle": "2025-03-19T17:41:47.721890Z",
          "shell.execute_reply.started": "2025-03-19T17:41:47.713408Z",
          "shell.execute_reply": "2025-03-19T17:41:47.720972Z"
        },
        "id": "4QKDIrAy1QwC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F1-score on submitted predictions = Score: 0.82439**"
      ],
      "metadata": {
        "id": "RrIGyeHn1QwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "aE7b4P-e1QwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Not surprisingly, the fine-tunned DistilBERT gave the highest score. Speaking of neural network trained from scratch, perhaps we should have tried a more complex architecture or performed more detailed EDA to make its prediction outperform classical ML models. In terms of quality/resources Logistic Regression is the best choice, because it generates predictions much faster than fine-tuned Neural Network and it is not so much worse. For me it was difficult to understand optimal format of features' encoding.**"
      ],
      "metadata": {
        "id": "jw5cTmC01QwC"
      }
    }
  ]
}